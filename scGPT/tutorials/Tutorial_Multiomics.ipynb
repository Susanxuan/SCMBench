{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944c58ab",
   "metadata": {},
   "source": [
    "# Fine-tuning on Pre-trained Model for Multiomic Integration\n",
    "In this tutorial, we demonstrate how to fine-tune a pre-trained model for multiomic integration. We use the BMMC dataset as an example for RNA and protein abundance data integration from CITE-seq. The BMMC dataset consists of multiple batches by donor origin. In the paired integration setting, each cell contains both RNA and protein measurements. We fine-tune on the pre-trained whole-body model.\n",
    "\n",
    "We summarize the fine-tuning pipeline in the following steps, which can be used as a general recipe for finetuning on integration tasks and beyond: \n",
    "\n",
    "     1. Specify hyper-parameter setup for integration task\n",
    "     \n",
    "     2. Load and pre-process data\n",
    "     \n",
    "     3. Load the pre-trained scGPT model\n",
    "     \n",
    "     4. Finetune scGPT with task-specific objectives\n",
    "     \n",
    "     5. Evaluate fine-tuned scGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190fb7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ailab/user/liuxinyuan/.local/lib/python3.9/site-packages/scanpy/_settings.py:450: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "#from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "# import scvi\n",
    "import numpy as np\n",
    "# import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from scgpt import prepare_data, prepare_dataloader, define_wandb_metrcis, evaluate, eval_testdata, train\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch\n",
    "from scgpt.model import MultiOmicTransformerModel\n",
    "\n",
    "import scgpt as scg\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "from scgpt.tokenizer import random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3931b62",
   "metadata": {},
   "source": [
    "## Step1: Specify hyper-parameter setup for integration task\n",
    "Here we provide some hyper-parameter recommendations for the multiomic integration task. Note that the BMMC dataset contains multiple batches to be integrated. Therefore, in addition to the default gene modelling objectives, we also turn on DAR objectives specifically to faciliate batch integration. We also turn on the use_mod argument as default to ensure that the model is modality-aware during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e9da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    task = 'multiomic',\n",
    "    seed=42,\n",
    "    dataset_name='SCMBench', # Dataset name \"BMMC\"\n",
    "    do_train=True, # Flag to indicate whether to do update model parameters during training\n",
    "    load_model=\"../save/scGPT_human\", # Path to pre-trained model\n",
    "    freeze = False, #freeze\n",
    "    GEP=True, # Gene expression modelling\n",
    "    GEPC=True, # Gene expression modelling for cell objective\n",
    "    CLS=False,\n",
    "    ESC=False,\n",
    "    DAR = True, # DAR objective weight for batch correction\n",
    "    DSBN = False,  # Domain-spec batchnorm,\n",
    "    mask_ratio=0.4, # Default mask ratio\n",
    "    explicit_zero_prob = False,  # whether explicit bernoulli for zeros\n",
    "    ecs_thres=0,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0,\n",
    "    use_batch_labels = True,\n",
    "    use_mod = True,\n",
    "    per_seq_batch_sample = False,\n",
    "    epochs=25, # Default number of epochs for fine-tuning #25\n",
    "    input_layer_key = \"X_binned\", # Default expression value binning in data pre-processing\n",
    "    n_bins=51, # Default number of bins for value binning in data pre-processing\n",
    "    n_hvg = 1200,  # Default number of highly variable genes\n",
    "    n_hvp = 4000,\n",
    "    max_seq_len = 4001, # # Default n_hvg+1\n",
    "    lr=1e-3, # Default learning rate for fine-tuning\n",
    "    batch_size=16, # Default batch size for fine-tuning\n",
    "    layer_size=512,\n",
    "    nlayers=4,\n",
    "    nhead=8, # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2, # Default dropout rate during model fine-tuning\n",
    "    schedule_ratio=0.95,  # Default rate for learning rate decay\n",
    "    save_eval_interval=5, # Default model evaluation interval\n",
    "    log_interval=100, # Default log interval\n",
    "    fast_transformer=True, # Default setting\n",
    "    pre_norm=False, # Default setting\n",
    "    amp=True,  # Default setting: Automatic Mixed Precision\n",
    "    pad_token = \"<pad>\",\n",
    "    mask_value = -1,\n",
    "    pad_value = -2,\n",
    "    include_zero_gene = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9e7e294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/nas/user/yixuan/scGPT/tutorials/wandb/run-20240116_173444-b6337zfv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/18763105182/scGPT/runs/b6337zfv' target=\"_blank\">autumn-blaze-40</a></strong> to <a href='https://wandb.ai/18763105182/scGPT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/18763105182/scGPT' target=\"_blank\">https://wandb.ai/18763105182/scGPT</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/18763105182/scGPT/runs/b6337zfv' target=\"_blank\">https://wandb.ai/18763105182/scGPT/runs/b6337zfv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'multiomic', 'seed': 42, 'dataset_name': 'SCMBench', 'do_train': True, 'load_model': '../save/scGPT_human', 'freeze': False, 'GEP': True, 'GEPC': True, 'CLS': False, 'ESC': False, 'DAR': True, 'DSBN': False, 'mask_ratio': 0.4, 'explicit_zero_prob': False, 'ecs_thres': 0, 'dab_weight': 1.0, 'use_batch_labels': True, 'use_mod': True, 'per_seq_batch_sample': False, 'epochs': 25, 'input_layer_key': 'X_binned', 'n_bins': 51, 'n_hvg': 1200, 'n_hvp': 4000, 'max_seq_len': 4001, 'lr': 0.001, 'batch_size': 16, 'layer_size': 512, 'nlayers': 4, 'nhead': 8, 'dropout': 0.2, 'schedule_ratio': 0.95, 'save_eval_interval': 5, 'log_interval': 100, 'fast_transformer': True, 'pre_norm': False, 'amp': True, 'pad_token': '<pad>', 'mask_value': -1, 'pad_value': -2, 'include_zero_gene': False}\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")\n",
    "config = wandb.config\n",
    "print(config)\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "327a9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for input and preprocessing\n",
    "special_tokens = [config.pad_token, \"<cls>\", \"<eoc>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bf30635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to save/dev_SCMBench-Jan16-17-34\n"
     ]
    }
   ],
   "source": [
    "dataset_name = config.dataset_name\n",
    "save_dir = Path(f\"./save/dev_{dataset_name}-{time.strftime('%b%d-%H-%M')}/\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"save to {save_dir}\")\n",
    "logger = scg.logger\n",
    "scg.utils.add_file_handler(logger, save_dir / \"run.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26f7516",
   "metadata": {},
   "source": [
    "## Step 2: Load and pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653e6b7",
   "metadata": {},
   "source": [
    "### 2.1 Load the BMMC data\n",
    "Please download the data from https://drive.google.com/file/d/10RxboePS5p2Jj2Sfq1Ghzgqnl6nqPv5V/view?usp=sharing\n",
    "\n",
    "For the purpose of this tutorial, we selected a 12K+ cell subset from the BMMC dataset (originally 90K+ cells) to speed up training. More specifically, we filtered on the first 3 donors (batches) with B, Mono and T cell subtypes as shown in the data loading step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "469efeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir_name='10x-Multiome-Pbmc10k-small'\n",
    "dataset_dir_name='Chen-2019-small'\n",
    "input_rna_dir='/mnt/nas/user/yixuan/Multiomics-benchmark-main/data/download/'+dataset_dir_name+'/'+dataset_dir_name+'-RNA.h5ad'\n",
    "input_atac_dir='/mnt/nas/user/yixuan/Multiomics-benchmark-main/data/download/'+dataset_dir_name+'/'+dataset_dir_name+'-ATAC.h5ad'\n",
    "\n",
    "output_rna_dir='/mnt/nas/user/yixuan/Multiomics-benchmark-main/evaluation/workflow/scripts/scGPT-output/'+dataset_dir_name+'/'+dataset_dir_name+'-rna.csv'\n",
    "output_atac_dir='/mnt/nas/user/yixuan/Multiomics-benchmark-main/evaluation/workflow/scripts/scGPT-output/'+dataset_dir_name+'/'+dataset_dir_name+'-atac.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f55e4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nas/user/yixuan/Multiomics-benchmark-main/data/download/Chen-2019-small/Chen-2019-small-RNA.h5ad\n",
      "/mnt/nas/user/yixuan/Multiomics-benchmark-main/evaluation/workflow/scripts/scGPT-output/Chen-2019-small/Chen-2019-small-rna.csv\n"
     ]
    }
   ],
   "source": [
    "print(input_rna_dir)\n",
    "print(output_rna_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14f8edf6-4c5d-4056-8954-c11c737a50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n"
     ]
    }
   ],
   "source": [
    "if dataset_name == 'BMMC':\n",
    "    adata = sc.read('scmdata/BMMC_processed.h5ad')\n",
    "    # subset to first 3 donors with B, Mono and T cell subtypes\n",
    "    adata = adata[adata.obs.DonorID.isin([10886, 11466, 12710]) & adata.obs.cell_type.isin(np.unique(adata.obs.cell_type.values)[:17])]\n",
    "    adata.obs[\"celltype\"] = adata.obs[\"cell_type\"].astype(str).astype('category')\n",
    "    adata.var[\"gene_name\"] = adata.var.index.tolist()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoded_batch = le.fit_transform(adata.obs['batch'].values)\n",
    "    adata.obs[\"batch_id\"] =  encoded_batch\n",
    "    adata.obs[\"str_batch\"] = adata.obs[\"batch_id\"].astype('category')\n",
    "    adata_protein = adata[:, adata.var.feature_types.isin(['ADT'])].copy()\n",
    "    adata_protein.var.index = ['p_' + i for i in adata_protein.var.index]\n",
    "    adata = adata[:, adata.var.feature_types.isin(['GEX'])].copy()\n",
    "    data_is_raw = False\n",
    "if dataset_name == 'SCMBench':\n",
    "    adata = anndata.read_h5ad(input_rna_dir)\n",
    "    adata_protein = anndata.read_h5ad(input_atac_dir)\n",
    "    adata.obs[\"celltype\"] = adata.obs[\"cell_type\"].astype(str).astype('category')\n",
    "    adata.var[\"gene_name\"] = adata.var.index.tolist()\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoded_batch = le.fit_transform(adata.obs['domain'].values)\n",
    "    adata.obs[\"batch_id\"] =  encoded_batch\n",
    "    adata.obs[\"str_batch\"] = adata.obs[\"batch_id\"].astype('category')\n",
    "    data_is_raw = False\n",
    "    print('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae0a311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>chromStart</th>\n",
       "      <th>chromEnd</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>thickStart</th>\n",
       "      <th>thickEnd</th>\n",
       "      <th>itemRgb</th>\n",
       "      <th>blockCount</th>\n",
       "      <th>...</th>\n",
       "      <th>havana_gene</th>\n",
       "      <th>tag</th>\n",
       "      <th>genome</th>\n",
       "      <th>n_counts</th>\n",
       "      <th>highly_variable</th>\n",
       "      <th>highly_variable_rank</th>\n",
       "      <th>means</th>\n",
       "      <th>variances</th>\n",
       "      <th>variances_norm</th>\n",
       "      <th>gene_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0610009B22Rik</th>\n",
       "      <td>chr11</td>\n",
       "      <td>51685385</td>\n",
       "      <td>51688874</td>\n",
       "      <td>0610009B22Rik</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000005608.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>159.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>1.126013</td>\n",
       "      <td>0610009B22Rik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009E02Rik</th>\n",
       "      <td>chr2</td>\n",
       "      <td>26445695</td>\n",
       "      <td>26459390</td>\n",
       "      <td>0610009E02Rik</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000012797.1</td>\n",
       "      <td>overlapping_locus</td>\n",
       "      <td>mm10</td>\n",
       "      <td>136.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4910.0</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>1.023411</td>\n",
       "      <td>0610009E02Rik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610009L18Rik</th>\n",
       "      <td>chr11</td>\n",
       "      <td>120348677</td>\n",
       "      <td>120351190</td>\n",
       "      <td>0610009L18Rik</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000004146.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>152.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.020403</td>\n",
       "      <td>1.082735</td>\n",
       "      <td>0610009L18Rik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610010F05Rik</th>\n",
       "      <td>chr11</td>\n",
       "      <td>23564960</td>\n",
       "      <td>23633639</td>\n",
       "      <td>0610010F05Rik</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000005276.5</td>\n",
       "      <td>ncRNA_host</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1448.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6513.0</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.197176</td>\n",
       "      <td>1.004244</td>\n",
       "      <td>0610010F05Rik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0610040B10Rik</th>\n",
       "      <td>chr5</td>\n",
       "      <td>143329246</td>\n",
       "      <td>143332704</td>\n",
       "      <td>0610040B10Rik</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000022920.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>76.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3092.0</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>1.058338</td>\n",
       "      <td>0610040B10Rik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn1r14</th>\n",
       "      <td>chr6</td>\n",
       "      <td>57231685</td>\n",
       "      <td>57240885</td>\n",
       "      <td>Vmn1r14</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000039911.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Vmn1r14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn1r181</th>\n",
       "      <td>chr7</td>\n",
       "      <td>23974614</td>\n",
       "      <td>23988139</td>\n",
       "      <td>Vmn1r181</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000038015.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7171.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Vmn1r181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn1r193</th>\n",
       "      <td>chr13</td>\n",
       "      <td>22213671</td>\n",
       "      <td>22223160</td>\n",
       "      <td>Vmn1r193</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000000481.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7186.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Vmn1r193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn1r68</th>\n",
       "      <td>chr7</td>\n",
       "      <td>10507397</td>\n",
       "      <td>10558485</td>\n",
       "      <td>Vmn1r68</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000038515.3</td>\n",
       "      <td>overlapping_locus</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7177.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Vmn1r68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn1r82</th>\n",
       "      <td>chr7</td>\n",
       "      <td>12300429</td>\n",
       "      <td>12308582</td>\n",
       "      <td>Vmn1r82</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>OTTMUSG00000038261.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mm10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Vmn1r82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               chrom  chromStart   chromEnd           name score strand  \\\n",
       "genes                                                                     \n",
       "0610009B22Rik  chr11    51685385   51688874  0610009B22Rik     .      -   \n",
       "0610009E02Rik   chr2    26445695   26459390  0610009E02Rik     .      +   \n",
       "0610009L18Rik  chr11   120348677  120351190  0610009L18Rik     .      +   \n",
       "0610010F05Rik  chr11    23564960   23633639  0610010F05Rik     .      -   \n",
       "0610040B10Rik   chr5   143329246  143332704  0610040B10Rik     .      +   \n",
       "...              ...         ...        ...            ...   ...    ...   \n",
       "Vmn1r14         chr6    57231685   57240885        Vmn1r14     .      +   \n",
       "Vmn1r181        chr7    23974614   23988139       Vmn1r181     .      +   \n",
       "Vmn1r193       chr13    22213671   22223160       Vmn1r193     .      -   \n",
       "Vmn1r68         chr7    10507397   10558485        Vmn1r68     .      -   \n",
       "Vmn1r82         chr7    12300429   12308582        Vmn1r82     .      +   \n",
       "\n",
       "              thickStart thickEnd itemRgb blockCount  ...  \\\n",
       "genes                                                 ...   \n",
       "0610009B22Rik          .        .       .          .  ...   \n",
       "0610009E02Rik          .        .       .          .  ...   \n",
       "0610009L18Rik          .        .       .          .  ...   \n",
       "0610010F05Rik          .        .       .          .  ...   \n",
       "0610040B10Rik          .        .       .          .  ...   \n",
       "...                  ...      ...     ...        ...  ...   \n",
       "Vmn1r14                .        .       .          .  ...   \n",
       "Vmn1r181               .        .       .          .  ...   \n",
       "Vmn1r193               .        .       .          .  ...   \n",
       "Vmn1r68                .        .       .          .  ...   \n",
       "Vmn1r82                .        .       .          .  ...   \n",
       "\n",
       "                        havana_gene                tag genome n_counts  \\\n",
       "genes                                                                    \n",
       "0610009B22Rik  OTTMUSG00000005608.1                NaN   mm10    159.0   \n",
       "0610009E02Rik  OTTMUSG00000012797.1  overlapping_locus   mm10    136.0   \n",
       "0610009L18Rik  OTTMUSG00000004146.2                NaN   mm10    152.0   \n",
       "0610010F05Rik  OTTMUSG00000005276.5         ncRNA_host   mm10   1448.0   \n",
       "0610040B10Rik  OTTMUSG00000022920.2                NaN   mm10     76.0   \n",
       "...                             ...                ...    ...      ...   \n",
       "Vmn1r14        OTTMUSG00000039911.3                NaN   mm10      1.0   \n",
       "Vmn1r181       OTTMUSG00000038015.2                NaN   mm10      1.0   \n",
       "Vmn1r193       OTTMUSG00000000481.3                NaN   mm10      1.0   \n",
       "Vmn1r68        OTTMUSG00000038515.3  overlapping_locus   mm10      1.0   \n",
       "Vmn1r82        OTTMUSG00000038261.3                NaN   mm10      1.0   \n",
       "\n",
       "              highly_variable highly_variable_rank     means variances  \\\n",
       "genes                                                                    \n",
       "0610009B22Rik            True               1528.0  0.017301  0.022228   \n",
       "0610009E02Rik            True               4910.0  0.014799  0.017193   \n",
       "0610009L18Rik            True               2314.0  0.016540  0.020403   \n",
       "0610010F05Rik            True               6513.0  0.157563  0.197176   \n",
       "0610040B10Rik            True               3092.0  0.008270  0.009726   \n",
       "...                       ...                  ...       ...       ...   \n",
       "Vmn1r14                  True               7168.0  0.000109  0.000109   \n",
       "Vmn1r181                 True               7171.0  0.000109  0.000109   \n",
       "Vmn1r193                 True               7186.0  0.000109  0.000109   \n",
       "Vmn1r68                  True               7177.0  0.000109  0.000109   \n",
       "Vmn1r82                  True               7500.0  0.000109  0.000109   \n",
       "\n",
       "               variances_norm      gene_name  \n",
       "genes                                         \n",
       "0610009B22Rik        1.126013  0610009B22Rik  \n",
       "0610009E02Rik        1.023411  0610009E02Rik  \n",
       "0610009L18Rik        1.082735  0610009L18Rik  \n",
       "0610010F05Rik        1.004244  0610010F05Rik  \n",
       "0610040B10Rik        1.058338  0610040B10Rik  \n",
       "...                       ...            ...  \n",
       "Vmn1r14              1.000000        Vmn1r14  \n",
       "Vmn1r181             1.000000       Vmn1r181  \n",
       "Vmn1r193             1.000000       Vmn1r193  \n",
       "Vmn1r68              1.000000        Vmn1r68  \n",
       "Vmn1r82              1.000000        Vmn1r82  \n",
       "\n",
       "[8000 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bfe331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_mod:\n",
    "    gene_rna_df = pd.DataFrame(index = adata.var.index.tolist())\n",
    "    gene_rna_df['mod'] = 'RNA'\n",
    "    gene_protein_df = pd.DataFrame(index = adata_protein.var.index.tolist())\n",
    "    gene_protein_df['mod'] = 'Protein'\n",
    "    gene_loc_df = pd.concat([gene_rna_df, gene_protein_df])\n",
    "    gene_loc_df['mod'] = gene_loc_df['mod'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7371ebc",
   "metadata": {},
   "source": [
    "### 2.2 Cross-check gene set with the pre-trained model \n",
    "Note that we retain the common gene set between the data and the pre-trained model for further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cc7d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - match 4/8000 genes in vocabulary of size 60697.\n"
     ]
    }
   ],
   "source": [
    "if config.load_model is not None:\n",
    "    model_dir = Path(config.load_model)\n",
    "    model_config_file = model_dir / \"args.json\"\n",
    "    model_file = model_dir / \"best_model.pt\"\n",
    "    vocab_file = model_dir / \"vocab.json\"\n",
    "\n",
    "    vocab = GeneVocab.from_file(vocab_file)\n",
    "    for s in special_tokens:\n",
    "        if s not in vocab:\n",
    "            vocab.append_token(s)\n",
    "\n",
    "    adata.var[\"id_in_vocab\"] = [\n",
    "        1 if gene in vocab else -1 for gene in adata.var[\"gene_name\"]\n",
    "    ]\n",
    "    gene_ids_in_vocab = np.array(adata.var[\"id_in_vocab\"])\n",
    "    logger.info(\n",
    "        f\"match {np.sum(gene_ids_in_vocab >= 0)}/{len(gene_ids_in_vocab)} genes \"\n",
    "        f\"in vocabulary of size {len(vocab)}.\"\n",
    "    )\n",
    "    old_vocab = vocab\n",
    "embsize = config.layer_size\n",
    "nhead = config.nhead\n",
    "nlayers = config.nlayers\n",
    "d_hid = config.layer_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f414d",
   "metadata": {},
   "source": [
    "### 2.3 Pre-process the data\n",
    "We follow the standardized pipline of depth normalization, log normalization, and highly vairable gene (HVG) selection for data pre-processing. We further introduce value binning to obtain the relative expressions of each HVG. Given multiple sequencing modalities, we perform the pre-processing steps on each individual modality first, and then combine them into multi-modal sequences as model input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32228422",
   "metadata": {},
   "source": [
    "#### 2.3.1 Pre-process the RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69be564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Filtering genes by counts ...\n",
      "scGPT - INFO - Filtering cells by counts ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Normalizing total counts ...\n",
      "scGPT - INFO - Subsetting highly variable genes ...\n",
      "scGPT - WARNING - No batch_key is provided, will use all cells for HVG selection.\n",
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=1,  # step 1\n",
    "    filter_cell_by_counts=1,  # step 2\n",
    "    normalize_total=1e4,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=data_is_raw,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=config.n_hvg,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=\"seurat_v3\" if data_is_raw else \"cell_ranger\",\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor(adata, batch_key=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12efe68e",
   "metadata": {},
   "source": [
    "#### 2.3.2 Pre-process the Protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a72dc9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - Binning data ...\n"
     ]
    }
   ],
   "source": [
    "preprocessor_protein = Preprocessor(\n",
    "    use_key=\"X\",  # the key in adata.layers to use as raw data\n",
    "    filter_gene_by_counts=0,  # step 1\n",
    "    filter_cell_by_counts=False,  # step 2\n",
    "    normalize_total=False,  # 3. whether to normalize the raw data and to what sum\n",
    "    result_normed_key=\"X_normed\",  # the key in adata.layers to store the normalized data\n",
    "    log1p=False,  # 4. whether to log1p the normalized data\n",
    "    result_log1p_key=\"X_log1p\",\n",
    "    subset_hvg=False,  # 5. whether to subset the raw data to highly variable genes\n",
    "    hvg_flavor=None,\n",
    "    binning=config.n_bins,  # 6. whether to bin the raw data and to what number of bins\n",
    "    result_binned_key=\"X_binned\",  # the key in adata.layers to store the binned data\n",
    ")\n",
    "preprocessor_protein(adata_protein, batch_key=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e11257",
   "metadata": {},
   "source": [
    "#### 2.3.3 Combine RNA, and Protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ab9f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = np.concatenate([adata.layers[\"X_binned\"], adata_protein.layers[\"X_binned\"]], axis=1)\n",
    "adata = AnnData(\n",
    "    X=data_combined,\n",
    "    obs=adata.obs,\n",
    "    var=pd.DataFrame(index=adata.var_names.tolist() + adata_protein.var_names.tolist()),\n",
    "    layers={\"X_binned\": data_combined,}\n",
    ")\n",
    "adata.var[\"gene_name\"] = adata.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f717788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 9190 × 81200\n",
       "    obs: 'domain', 'protocol', 'dataset', 'cell_type', 'celltype', 'batch_id', 'str_batch', 'n_counts'\n",
       "    var: 'gene_name'\n",
       "    layers: 'X_binned'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "372f68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.per_seq_batch_sample:\n",
    "    # sort the adata by batch_id in advance\n",
    "    adata_sorted = adata[adata.obs[\"batch_id\"].argsort()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c2a1c",
   "metadata": {},
   "source": [
    "### 2.4 Tokenize the input data for model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "116c8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_counts = (\n",
    "    adata.layers[config.input_layer_key].A\n",
    "    if issparse(adata.layers[config.input_layer_key])\n",
    "    else adata.layers[config.input_layer_key]\n",
    ")\n",
    "genes = adata.var[\"gene_name\"].tolist()\n",
    "\n",
    "celltypes_labels = adata.obs[\"cell_type\"].tolist()  # make sure count from 0\n",
    "num_types = len(set(celltypes_labels))\n",
    "celltypes_labels = np.array(celltypes_labels)\n",
    "\n",
    "batch_ids = adata.obs[\"batch_id\"].tolist()\n",
    "num_batch_types = len(set(batch_ids))\n",
    "batch_ids = np.array(batch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9ac9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_mod:\n",
    "    mod_type = np.array([gene_loc_df.loc[g, 'mod'] for g in genes])\n",
    "    vocab_mod = Vocab(VocabPybind(np.unique(gene_loc_df['mod']).tolist() + special_tokens, None))\n",
    "    vocab_mod.set_default_index(vocab_mod[\"<pad>\"])\n",
    "    mod_type = np.array(vocab_mod(list(mod_type)), dtype=int)\n",
    "    ntokens_mod = len(vocab_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "753b6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_data,\n",
    "    valid_data,\n",
    "    train_celltype_labels,\n",
    "    valid_celltype_labels,\n",
    "    train_batch_labels,\n",
    "    valid_batch_labels,\n",
    ") = train_test_split(\n",
    "    all_counts, celltypes_labels, batch_ids, test_size=0.1, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a942b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max num of non_zero genes: 2881\n",
      "min num of non_zero genes: 167\n",
      "average num of non_zero genes: 864.1363801233224\n",
      "99% quantile num of non_zero genes: 2386.300000000002\n",
      "max original values: 50\n",
      "average original non_zero values: 25.273262721776923\n",
      "99% quantile original non_zero values: 49.0\n",
      "num of celltypes: 22\n"
     ]
    }
   ],
   "source": [
    "num_of_non_zero_genes = [\n",
    "    np.count_nonzero(train_data[i]) for i in range(train_data.shape[0])\n",
    "]\n",
    "print(f\"max num of non_zero genes: {np.max(num_of_non_zero_genes)}\")\n",
    "print(f\"min num of non_zero genes: {np.min(num_of_non_zero_genes)}\")\n",
    "print(f\"average num of non_zero genes: {np.mean(num_of_non_zero_genes)}\")\n",
    "print(\n",
    "    f\"99% quantile num of non_zero genes: {np.quantile(num_of_non_zero_genes, 0.99)}\"\n",
    ")\n",
    "print(f\"max original values: {np.max(train_data)}\")\n",
    "print(\n",
    "    f\"average original non_zero values: {np.mean(train_data[np.nonzero(train_data)])}\"\n",
    ")\n",
    "print(\n",
    "    f\"99% quantile original non_zero values: {np.quantile(train_data[np.nonzero(train_data)], 0.99)}\"\n",
    ")\n",
    "print(f\"num of celltypes: {num_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fd4b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.load_model is None:\n",
    "    vocab = Vocab(VocabPybind(genes + special_tokens, None))\n",
    "    vocab.set_default_index(vocab[\"<pad>\"])\n",
    "    gene_ids = np.array(vocab(genes), dtype=int)\n",
    "else:\n",
    "    pretrained_genes = [g for g in genes + special_tokens if g in old_vocab]\n",
    "    new_genes = [g for g in genes + special_tokens if g not in old_vocab]\n",
    "    gene_ids_pretrained = np.array(old_vocab(pretrained_genes), dtype=int)\n",
    "    # https://discuss.pytorch.org/t/expand-an-existing-embedding-and-linear-layer-nan-loss-value/55670/2\n",
    "    # Retrieve pretrained weights\n",
    "    vocab = Vocab(VocabPybind(pretrained_genes + new_genes, None))\n",
    "    vocab.set_default_index(vocab[\"<pad>\"])\n",
    "    gene_ids = np.array(vocab(genes), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b578ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scGPT - INFO - train set number of samples: 8271, \n",
      "\t feature length: 2882\n",
      "scGPT - INFO - valid set number of samples: 919, \n",
      "\t feature length: 2682\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = tokenize_and_pad_batch(\n",
    "    train_data,\n",
    "    gene_ids,\n",
    "    max_len=config.max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=config.pad_token,\n",
    "    pad_value=config.pad_value,\n",
    "    append_cls=True,  # append <cls> token at the beginning\n",
    "    include_zero_gene=config.include_zero_gene,\n",
    "    mod_type=mod_type if config.use_mod else None,\n",
    "    vocab_mod=vocab_mod if config.use_mod else None,\n",
    ")\n",
    "tokenized_valid = tokenize_and_pad_batch(\n",
    "    valid_data,\n",
    "    gene_ids,\n",
    "    max_len=config.max_seq_len,\n",
    "    vocab=vocab,\n",
    "    pad_token=config.pad_token,\n",
    "    pad_value=config.pad_value,\n",
    "    append_cls=True,\n",
    "    include_zero_gene=config.include_zero_gene,\n",
    "    mod_type=mod_type if config.use_mod else None,\n",
    "    vocab_mod=vocab_mod if config.use_mod else None,\n",
    ")\n",
    "logger.info(\n",
    "    f\"train set number of samples: {tokenized_train['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_train['genes'].shape[1]}\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"valid set number of samples: {tokenized_valid['genes'].shape[0]}, \"\n",
    "    f\"\\n\\t feature length: {tokenized_valid['genes'].shape[1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f78ec",
   "metadata": {},
   "source": [
    "## Step 3: Load the pre-trained scGPT model\n",
    "Note that for multiomic integration, since the pre-trained model does not include the ATAC and protein tokens, we expand the embedding layer by adding these new tokens. We inherit only the gene embedding layer from the pre-trained model, and train rest of the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd642466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d57aaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOmicTransformerModel(\n",
      "  (encoder): GeneEncoder(\n",
      "    (embedding): Embedding(81203, 512, padding_idx=2)\n",
      "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (value_encoder): ContinuousValueEncoder(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (linear1): Linear(in_features=1, out_features=512, bias=True)\n",
      "    (activation): ReLU()\n",
      "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (batch_encoder): BatchLabelEncoder(\n",
      "    (embedding): Embedding(1, 512)\n",
      "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (mod_encoder): BatchLabelEncoder(\n",
      "    (embedding): Embedding(5, 512, padding_idx=2)\n",
      "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): FlashTransformerEncoderLayer(\n",
      "        (self_attn): FlashMHA(\n",
      "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (inner_attn): FlashAttention()\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): FlashTransformerEncoderLayer(\n",
      "        (self_attn): FlashMHA(\n",
      "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (inner_attn): FlashAttention()\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): FlashTransformerEncoderLayer(\n",
      "        (self_attn): FlashMHA(\n",
      "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (inner_attn): FlashAttention()\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): FlashTransformerEncoderLayer(\n",
      "        (self_attn): FlashMHA(\n",
      "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "          (inner_attn): FlashAttention()\n",
      "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ExprDecoder(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (cls_decoder): ClsDecoder(\n",
      "    (_decoder): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (mvc_decoder): MVCDecoder(\n",
      "    (gene2query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (query_activation): Sigmoid()\n",
      "    (W): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "  )\n",
      "  (grad_reverse_discriminator): AdversarialDiscriminator(\n",
      "    (_decoder): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (4): LeakyReLU(negative_slope=0.01)\n",
      "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (out_layer): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (sim): Similarity(\n",
      "    (cos): CosineSimilarity()\n",
      "  )\n",
      "  (creterion_cce): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_number = 1\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{device_number}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model_dict = torch.load(model_file)\n",
    "ntokens = len(vocab)  # size of vocabulary\n",
    "model = MultiOmicTransformerModel(\n",
    "    ntokens,\n",
    "    embsize,\n",
    "    nhead,\n",
    "    d_hid, \n",
    "    nlayers,\n",
    "    vocab=vocab,\n",
    "    dropout=config.dropout,\n",
    "    pad_token=config.pad_token,\n",
    "    pad_value=config.pad_value,\n",
    "    do_mvc=config.GEPC,\n",
    "    do_dab=config.DAR,\n",
    "    use_batch_labels=config.use_batch_labels,\n",
    "    num_batch_labels=num_batch_types,\n",
    "    domain_spec_batchnorm=config.DSBN,\n",
    "    n_input_bins=config.n_bins,\n",
    "    ecs_threshold=config.ecs_thres,\n",
    "    explicit_zero_prob=config.explicit_zero_prob,\n",
    "    use_fast_transformer=config.fast_transformer,\n",
    "    pre_norm=config.pre_norm,\n",
    "    use_mod=config.use_mod,\n",
    "    ntokens_mod=ntokens_mod if config.use_mod else None,\n",
    "    vocab_mod=vocab_mod if config.use_mod else None,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    pretrained_emb_weights = model_dict['encoder.embedding.weight'][gene_ids_pretrained, :]\n",
    "    model.encoder.embedding.weight.data[:len(pretrained_genes), :] = pretrained_emb_weights\n",
    "    model.encoder.enc_norm.weight.data = model_dict['encoder.enc_norm.weight']\n",
    "ntokens = len(vocab)\n",
    "\n",
    "model.to(device)\n",
    "wandb.watch(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecff528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.GEP and config.GEPC:\n",
    "    criterion_gep_gepc = masked_mse_loss\n",
    "if config.CLS:\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "if config.DAR:\n",
    "    criterion_dab = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=config.lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d9e08",
   "metadata": {},
   "source": [
    "## Step 4: Finetune scGPT with task-specific objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "62c9cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random masking at epoch   1, ratio of masked values in train:  0.3995\n",
      "scGPT - INFO - | epoch   1 | 100/517 batches | lr 0.00100 | ms/batch 115.39 | loss 10727.34 | gep 374.71 |gepc 10352.62 |dar  0.00 |\n",
      "scGPT - INFO - | epoch   1 | 200/517 batches | lr 0.00100 | ms/batch 108.74 | loss 404.51 | gep 204.75 |gepc 199.76 |dar  0.00 |\n",
      "scGPT - INFO - | epoch   1 | 300/517 batches | lr 0.00100 | ms/batch 107.73 | loss 403.48 | gep 205.22 |gepc 198.25 |dar  0.00 |\n",
      "scGPT - INFO - | epoch   1 | 400/517 batches | lr 0.00100 | ms/batch 109.04 | loss 402.59 | gep 204.77 |gepc 197.83 |dar  0.00 |\n",
      "scGPT - INFO - | epoch   1 | 500/517 batches | lr 0.00100 | ms/batch 111.16 | loss 403.10 | gep 204.85 |gepc 198.25 |dar  0.00 |\n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - | end of epoch   1 | time: 58.97s | valid loss 204.7640 | \n",
      "scGPT - INFO - -----------------------------------------------------------------------------------------\n",
      "scGPT - INFO - Best model with score 204.7640\n",
      "random masking at epoch   2, ratio of masked values in train:  0.3995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 35\u001b[0m\n\u001b[1;32m     25\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m prepare_dataloader(\n\u001b[1;32m     26\u001b[0m     valid_data_pt,\n\u001b[1;32m     27\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     per_seq_batch_sample\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mper_seq_batch_sample\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdo_train:\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion_gep_gepc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_gep_gepc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGEPC\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion_dab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_dab\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDAR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m     51\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     52\u001b[0m     loader\u001b[38;5;241m=\u001b[39mvalid_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start_time\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/scGPT/tutorials/../scgpt/trainer.py:309\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader, vocab, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config, logger, epoch)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    304\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    305\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound infinite gradient. This may be caused by the gradient \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaler. The current scale is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler\u001b[38;5;241m.\u001b[39mget_scale()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This warning \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan be ignored if no longer occurs after autoscaling of the scaler.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m         )\n\u001b[0;32m--> 309\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    312\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog(metrics_to_log)\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:341\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 341\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:288\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "best_avg_bio = 0.0\n",
    "best_model = None\n",
    "define_wandb_metrcis()\n",
    "\n",
    "for epoch in range(1, config.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train_data_pt, valid_data_pt = prepare_data(\n",
    "        tokenized_train=tokenized_train, \n",
    "        tokenized_valid=tokenized_valid, \n",
    "        train_batch_labels=train_batch_labels,\n",
    "        valid_batch_labels=valid_batch_labels,\n",
    "        config=config,\n",
    "        epoch=epoch,\n",
    "        sort_seq_batch=config.per_seq_batch_sample)\n",
    "    \n",
    "    train_loader = prepare_dataloader(\n",
    "        train_data_pt,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        intra_domain_shuffle=False,\n",
    "        drop_last=False,\n",
    "        per_seq_batch_sample=config.per_seq_batch_sample\n",
    "    )\n",
    "    valid_loader = prepare_dataloader(\n",
    "        valid_data_pt,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        intra_domain_shuffle=False,\n",
    "        drop_last=False,\n",
    "        per_seq_batch_sample=config.per_seq_batch_sample\n",
    "    )\n",
    "\n",
    "    if config.do_train:\n",
    "        train(\n",
    "            model=model,\n",
    "            loader=train_loader,\n",
    "            vocab=vocab,\n",
    "            criterion_gep_gepc=criterion_gep_gepc if config.GEP and config.GEPC else None,\n",
    "            criterion_dab=criterion_dab if config.DAR else None,\n",
    "            criterion_cls=criterion_cls if config.CLS else None,\n",
    "            scaler=scaler,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            config=config,\n",
    "            logger=logger,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "    val_loss = evaluate(\n",
    "        model=model,\n",
    "        loader=valid_loader,\n",
    "        vocab=vocab,\n",
    "        criterion_gep_gepc=criterion_gep_gepc if config.GEP and config.GEPC else None,\n",
    "        criterion_dab=criterion_dab if config.DAR else None,\n",
    "        criterion_cls=criterion_cls if config.CLS else None,\n",
    "        device=device,\n",
    "        config=config,\n",
    "        epoch=epoch\n",
    "    )\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    logger.info(\"-\" * 89)\n",
    "    logger.info(\n",
    "        f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "        f\"valid loss {val_loss:5.4f} | \"\n",
    "    )\n",
    "    logger.info(\"-\" * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        logger.info(f\"Best model with score {best_val_loss:5.4f}\")\n",
    "\n",
    "    if epoch % config.save_eval_interval == 0 or epoch == config.epochs:\n",
    "        logger.info(f\"Saving model to {save_dir}\")\n",
    "        torch.save(best_model.state_dict(), save_dir / f\"model_e{best_model_epoch}.pt\")\n",
    "\n",
    "        # eval on testdata\n",
    "        # results = eval_testdata(\n",
    "        #     model = best_model,\n",
    "        #     adata_t = adata_sorted if config.per_seq_batch_sample else adata,\n",
    "        #     gene_ids = gene_ids,\n",
    "        #     vocab = vocab,\n",
    "        #     config = config,\n",
    "        #     logger = logger,\n",
    "        #     include_types=[\"cls\"],\n",
    "        # )\n",
    "        results,cell_embeddings = eval_testdata_save_embed(\n",
    "            model = best_model,\n",
    "            adata_t = adata_sorted if config.per_seq_batch_sample else adata,\n",
    "            gene_ids = gene_ids,\n",
    "            vocab = vocab,\n",
    "            config = config,\n",
    "            logger = logger,\n",
    "            include_types=[\"cls\"],\n",
    "        )\n",
    "\n",
    "        pd.DataFrame(cell_embeddings, index=adata.obs_names).to_csv(output_rna_dir, header=False)\n",
    "        pd.DataFrame(cell_embeddings, index=adata.obs_names).to_csv(output_atac_dir, header=False)\n",
    "\n",
    "        results[\"batch_umap\"].savefig(\n",
    "            save_dir / f\"embeddings_batch_umap[cls]_e{best_model_epoch}.png\", dpi=300\n",
    "        )\n",
    "\n",
    "        results[\"celltype_umap\"].savefig(\n",
    "            save_dir / f\"embeddings_celltype_umap[cls]_e{best_model_epoch}.png\", dpi=300\n",
    "        )\n",
    "        metrics_to_log = {\"test/\" + k: v for k, v in results.items()}\n",
    "        metrics_to_log[\"test/batch_umap\"] = wandb.Image(\n",
    "            str(save_dir / f\"embeddings_batch_umap[cls]_e{best_model_epoch}.png\"),\n",
    "            caption=f\"celltype avg_bio epoch {best_model_epoch}\",\n",
    "        )\n",
    "\n",
    "        metrics_to_log[\"test/celltype_umap\"] = wandb.Image(\n",
    "            str(save_dir / f\"embeddings_celltype_umap[cls]_e{best_model_epoch}.png\"),\n",
    "            caption=f\"celltype avg_bio epoch {best_model_epoch}\",\n",
    "        )\n",
    "        metrics_to_log[\"test/best_model_epoch\"] = best_model_epoch\n",
    "        wandb.log(metrics_to_log)\n",
    "        wandb.log({\"avg_bio\": results.get(\"avg_bio\", 0.0)})\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30430479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "torch.save(best_model.state_dict(), save_dir / \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f160cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:89: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe46a200739742869e1b3e5992328576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.101 MB of 3.101 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/user/yixuan/miniconda3/envs/scGPT/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_bio</td><td>▄▇▁▂█</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test/ARI_cluster/label</td><td>▃█▂▁▇</td></tr><tr><td>test/ASW_label</td><td>██▁▆▂</td></tr><tr><td>test/NMI_cluster/label</td><td>▆▄▁██</td></tr><tr><td>test/PCR_batch</td><td>█▁▁▁▂</td></tr><tr><td>test/avg_bio</td><td>▄▇▁▂█</td></tr><tr><td>test/best_model_epoch</td><td>▁▁▁▁▁</td></tr><tr><td>test/graph_conn</td><td>▅▂█▂▁</td></tr><tr><td>train/dab</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                        </td></tr><tr><td>train/gep</td><td>████▂▁▂▂▁▂▁▄▄▅▅▄                        </td></tr><tr><td>train/mvc</td><td>▃▂▂▁▁▁▁▂▁▁▁▂▃▃▆█                        </td></tr><tr><td>valid/loss</td><td>██▁▁▁▁▂▃▄                </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_bio</td><td>0.37036</td></tr><tr><td>epoch</td><td>25</td></tr><tr><td>test/ARI_cluster/label</td><td>0.30217</td></tr><tr><td>test/ASW_label</td><td>0.42382</td></tr><tr><td>test/NMI_cluster/label</td><td>0.38509</td></tr><tr><td>test/PCR_batch</td><td>0.08383</td></tr><tr><td>test/best_model_epoch</td><td>5</td></tr><tr><td>test/graph_conn</td><td>0.43749</td></tr><tr><td>train/dab</td><td>nan</td></tr><tr><td>train/gep</td><td>nan</td></tr><tr><td>train/mvc</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-wildflower-28</strong> at: <a href='https://wandb.ai/18763105182/scGPT/runs/7osohrwz' target=\"_blank\">https://wandb.ai/18763105182/scGPT/runs/7osohrwz</a><br/>Synced 6 W&B file(s), 10 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240116_140512-7osohrwz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "93153"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact = wandb.Artifact(f\"best_model\", type=\"model\")\n",
    "glob_str = os.path.join(save_dir, \"best_model.pt\")\n",
    "artifact.add_file(glob_str)\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "run.finish()\n",
    "wandb.finish()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5bf54-0d47-44da-a34b-4df3fac76124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
